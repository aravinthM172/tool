import pandas as pd
import requests
from bs4 import BeautifulSoup
from tqdm import tqdm
from twocaptcha import TwoCaptcha
from selenium import webdriver
from selenium.webdriver.common.by import By
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.service import Service
from time import sleep

# Read the Excel file
file_path = "Stockcheck.xlsx"  # Replace with your file path
data = pd.read_excel(file_path)

# User agent to mimic a web browser request
headers = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.45 Safari/537.36"
}

# Replace YOUR_2CAPTCHA_API_KEY with your actual 2Captcha API key
API_KEY = 'b071ecf83306c99a7edc8530448b6097'
solver = TwoCaptcha(API_KEY)


# Function to solve CAPTCHA using 2Captcha
def solve_captcha(driver):
    captcha_image_url = driver.find_element(By.XPATH,
                                            '/html/body/div/div[1]/div[3]/div/div/form/div[1]/div/div/div[1]/img').get_attribute(
        'src')
    captcha_token = solver.normal(captcha_image_url)
    print(f"Captcha Token: {captcha_token['code']}")
    captcha_entry_field = driver.find_element(By.ID, 'captchacharacters')
    captcha_entry_field.send_keys(captcha_token['code'])
    submit_button = driver.find_element(By.XPATH,
                                        '/html/body/div/div[1]/div[3]/div/div/form/div[2]/div/span/span/button')
    submit_button.click()
    sleep(2)


# Function to check availability with CAPTCHA handling
def check_availability_with_captcha(url, max_retries=3, initial_wait_time=5):
    retries = 0
    while retries < max_retries:
        try:
            response = requests.get(url, headers=headers)
            response.raise_for_status()  # Raise an exception for bad responses (4xx and 5xx)

            if retries > 0:
                wait_time = initial_wait_time * (2 ** (retries - 1))
                print(f"Waiting for {wait_time} seconds before retrying...")
                time.sleep(wait_time)

            if response.status_code == 200:
                soup = BeautifulSoup(response.content, "html.parser")
                driver.get(url)
                # Amazon availability
                if "amazon" in url:
                    # captcha check and resolve
                    captcha = driver.find_elements(By.XPATH, '/html/body/div/div[1]/div[3]/div/div/form')
                    if len(captcha) > 0:
                        driver.save_screenshot('captcha')
                        solve_captcha(driver)
                    availability = soup.find(id="availability")
                    if availability:
                        status = availability.get_text().strip()
                        print(status)
                        return status
                    else:
                        return "Information not found"
                # Flipkart availability
                elif "flipkart" in url:
                    availability = soup.find(class_="_16FRp0")
                    if availability:
                        status = availability.get_text().strip()
                        return status
                    else:
                        return "Out of stock"
                # Ajio availability
                elif "ajio" in url:
                    availability = soup.find(class_="prod-status")
                    if availability:
                        status = availability.get_text().strip()
                        return status
                    else:
                        return "Availability not found"
                else:
                    return "Unsupported URL"
        except requests.exceptions.RequestException as e:
            print(f"Error: {e}")
            retries += 1
            print(f"Retrying ({retries}/{max_retries})...")

    return "Failed to fetch the page."


chrome_options = webdriver.ChromeOptions()
# chrome_options.add_argument('--headless')
# chrome_options.add_argument(f'user-agent=f{headers["User-Agent"]}')
# chrome_options.add_argument('--no-sandbox')
# chrome_options.add_argument('--ignore-certificate-errors-spki-list')
# chrome_options.add_argument('--ignore-ssl-errors')
# chrome_options.add_argument('--disable-dev-shm-usage')
# chrome_options.add_argument("--disable-gpu")
# chrome_options.add_argument("--disable-logging")
# chrome_options.add_argument("--log-level=3")
# chrome_options.add_argument("--disable-3d-apis")
# chrome_options.add_argument("--output=/dev/null")

driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)

# Initialize a new webdriver for each URL
availability_list = []
with tqdm(total=len(data['url']), desc="Fetching Availability", unit="links",
          bar_format="{l_bar}{bar}| {n_fmt}/{total_fmt}") as pbar:
    for link in data['url']:
        availability = check_availability_with_captcha(link)
        availability_list.append(availability)
        pbar.update(1)

driver.quit()  # Close the webdriver after each URL

# Add availability to the DataFrame
data['Availability'] = availability_list

# Save the DataFrame with availability information to a new Excel file
output_file_path = "product_availability_with_captcha.xlsx"  # Output file name
data.to_excel(output_file_path, index=False)
print(f"Product availability data saved to '{output_file_path}'")
